{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b7b55deacbd9f66",
   "metadata": {},
   "source": [
    "# Conteggio Token\n",
    "\n",
    "### Utilità\n",
    "Il conteggio dei token è un'attività necessaria in diversi task, tra cui:\n",
    "* Preprocessing del testo per rispettare i limiti dei modelli\n",
    "* Ottimizzazione del contesto per modelli di completamento\n",
    "* Suddivisione di documenti lunghi\n",
    "* Determinazione del costo delle API\n",
    "* Prompt engineering e fine-tuning\n",
    "* Compattazione di informazioni strutturate\n",
    "* Interfacce utente o chatbot con limiti di lunghezza\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T15:16:14.900283Z",
     "start_time": "2025-10-29T15:16:14.893076Z"
    }
   },
   "source": [
    "# TikToken è un tokenizer open source fornito da OpenAI\n",
    "import tiktoken  # pip install tiktoken"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "1d4e72c4f7319a1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T15:16:19.949609Z",
     "start_time": "2025-10-29T15:16:14.908567Z"
    }
   },
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "5c7e56cad02cc689",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T15:16:20.579681Z",
     "start_time": "2025-10-29T15:16:20.568464Z"
    }
   },
   "source": [
    "# generazione token\n",
    "\n",
    "encoded = encoding.encode(\" vediamo vediamo vediamo quanti token si producono con questa frase e come possono essere eventualmente suddivise in token le singole parole, comprese parole inesistenti come frangullapporeo\")\n",
    "\n",
    "print(len(encoded), \"token\")\n",
    "print(encoded)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 token\n",
      "[13162, 26823, 13162, 26823, 13162, 26823, 8237, 72, 6602, 1784, 2443, 61144, 406, 40897, 65236, 319, 3063, 72713, 29919, 185272, 10332, 862, 1096, 306, 6602, 505, 6211, 1491, 58354, 11, 48769, 344, 58354, 173382, 421, 14989, 3063, 1441, 516, 754, 903, 164779]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "aff1e544bcac203c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T15:16:20.680058Z",
     "start_time": "2025-10-29T15:16:20.673087Z"
    }
   },
   "source": [
    "# decodifica del testo originale codificato\n",
    "\n",
    "encoding.decode(encoded)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' vediamo vediamo vediamo quanti token si producono con questa frase e come possono essere eventualmente suddivise in token le singole parole, comprese parole inesistenti come frangullapporeo'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "cfa028fbf67d1a95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T15:16:20.762316Z",
     "start_time": "2025-10-29T15:16:20.758309Z"
    }
   },
   "source": [
    "# stampa dei singoli token\n",
    "\n",
    "print(\"-\", end=\"\")\n",
    "for tok in encoded:\n",
    "    print(encoding.decode_single_token_bytes(tok).decode(\"utf-8\") + \"___\", end=\"\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ved___iamo___ ved___iamo___ ved___iamo___ quant___i___ token___ si___ produ___cono___ con___ questa___ frase___ e___ come___ possono___ essere___ eventualmente___ sud___div___ise___ in___ token___ le___ sing___ole___ parole___,___ compre___se___ parole___ ines___ist___enti___ come___ fr___ang___ull___app___oreo___"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "6e09b1a8d81ef102",
   "metadata": {},
   "source": [
    "### Analisi della tokenizzazione\n",
    "\n",
    "Notiamo la parola `producono` suddivisa nei token `produ` e `cono`    \n",
    "    \n",
    "La suddivisione in token non segue una logica morfologica o semantica del linguaggio naturale, ma è influenzata dalla frequenza statistica delle sottoparti delle parole presenti nel corpus di addestramento del modello. In questo caso, è probabile che \"produ\" e \"cono\" siano stati trovati come segmenti ricorrenti in altre parole (ad esempio, \"produ\" in \"produrre\" o \"produzione\", e \"cono\" in \"cono\" stesso o altre parole).    \n",
    "    \n",
    "Questo processo di creazione di **sub-words** avviene per:\n",
    "* **Frequenza statistica**: Il modello ha trovato \"produ\" e \"cono\" come unità più frequenti e quindi li tratta come segmenti indipendenti.\n",
    "* **Efficienza**: La tokenizzazione mira a ridurre il numero complessivo di token. Se \"produ\" e \"cono\" sono parti frequenti di altre parole, tenerli come token separati può ridurre il numero totale di token necessari nel vocabolario del modello.\n",
    "* **Flessibilità**: Dividere in token sub-word permette al modello di gestire parole rare o non viste durante l'addestramento. Se una parola come \"producono\" fosse estremamente rara, avere un token per ogni sotto-segmento (ad esempio, \"produ\" e \"cono\") permette al modello di gestirla anche se non ha visto esattamente quella parola completa durante l'addestramento.    \n",
    "    \n",
    "La parola inesistente utilizzata, `frangullapporeo` dimostra ancora meglio la capacità di tokenizzare anche parole non incontrate durante il processo di addestramento."
   ]
  },
  {
   "cell_type": "code",
   "id": "c75130acfcd3e4f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T15:16:20.783404Z",
     "start_time": "2025-10-29T15:16:20.781990Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
