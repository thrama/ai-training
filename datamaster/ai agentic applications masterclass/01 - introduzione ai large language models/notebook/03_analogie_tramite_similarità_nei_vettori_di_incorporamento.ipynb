{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cbcc11bef940c42",
   "metadata": {},
   "source": [
    "# Analisi delle analogie tramite similarità nei vettori di incorporamento\n",
    "\n",
    "## *\"re - uomo + donna = ...\"*"
   ]
  },
  {
   "cell_type": "code",
   "id": "67daff31b8d6a23e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T15:45:59.883902Z",
     "start_time": "2025-10-29T15:45:59.424713Z"
    }
   },
   "source": [
    "import gensim.downloader as api # Gensim è una libreria open source per la modellazione di argomenti \n",
    "                                # senza supervisione, l'indicizzazione di documenti, il recupero per \n",
    "                                # somiglianza e altre funzionalità di elaborazione del linguaggio \n",
    "                                # naturale\n",
    "                                # (la useremo per caricare un modello preaddestrato di Embeddings)\n",
    "                                # 'pip install gensim' per installarla\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "778909b82cd9c1ab",
   "metadata": {},
   "source": [
    "### Word2Vec\n",
    "\n",
    "Word2vec è una semplice rete neurale artificiale a due strati progettata per elaborare il linguaggio naturale.    \n",
    "Richiede in ingresso un corpus di testo e restituisce un insieme di vettori che rappresentano la distribuzione semantica delle parole nel testo.    \n",
    "Per ogni parola contenuta nel corpus, in modo univoco, viene costruito un vettore in modo da rappresentarla come un punto nello spazio multidimensionale creato (spazio latente del modello). In questo spazio, le parole saranno più vicine se riconosciute come semanticamente più simili.    "
   ]
  },
  {
   "cell_type": "code",
   "id": "383cbaf700a40837",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T15:46:19.784829Z",
     "start_time": "2025-10-29T15:45:59.888791Z"
    }
   },
   "source": [
    "# caricamento modello\n",
    "def load_word2vec_model():\n",
    "    print(\"Caricamento del modello Word2Vec...\")\n",
    "    return api.load('word2vec-google-news-300')  # modello pre-addestrata su una parte del dataset \n",
    "                                                 # di Google News \n",
    "                                                 # (circa 100 miliardi di parole). Gestisce uno \n",
    "                                                 # spazio latente a 300 dimensioni\n",
    "\n",
    "model = load_word2vec_model()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento del modello Word2Vec...\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "b0d4940a01671828",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T15:46:20.933434Z",
     "start_time": "2025-10-29T15:46:20.931001Z"
    }
   },
   "source": [
    "# funzione per la ricerca di parole analoghe/simili\n",
    "def find_analogy(model, word1, word2, word3):\n",
    "    try:\n",
    "        result = model.most_similar(positive=[word1, word3], negative=[word2], topn=1)\n",
    "        return result[0][0]\n",
    "    except KeyError:\n",
    "        return None"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "75758d4686ce872c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T15:46:22.218539Z",
     "start_time": "2025-10-29T15:46:20.944534Z"
    }
   },
   "source": [
    "find_analogy(model, \"king\", \"man\", \"woman\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queen'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "27a25e3e3ad6da7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T15:46:22.241722Z",
     "start_time": "2025-10-29T15:46:22.238780Z"
    }
   },
   "source": [
    "# funzione per il calcolo della similarità del coseno\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return 1 - (np.dot(vec1, vec2.T) / ((np.linalg.norm(vec1) * np.linalg.norm(vec2.T)) + 1e-8))  # n.b. abbiamo aggiunto \"1 - ...\" all'inizio per avere una misura di \"errore\": \n",
    "                                                                                                  # avremo così numeri tra 0 e 1 che ci indicheranno quanto sono differenti i due vettori"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "3cdf17e153249dcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T15:46:22.249291Z",
     "start_time": "2025-10-29T15:46:22.245983Z"
    }
   },
   "source": [
    "# analisi differenti modalità per il calcolo delle analogie\n",
    "def print_analogy_explanation(model, word1, word2, word3, result):\n",
    "    print(f\"\\nAnalogia: {word1} - {word2} + {word3} = ???    ... {result}\")\n",
    "\n",
    "    vec_relation = model[word1] - model[word2] + model[word3]\n",
    "\n",
    "    parola_simile = model.similar_by_vector(vec_relation, topn=1)[0][0]\n",
    "    similarity = cosine_similarity(vec_relation, model[result])\n",
    "\n",
    "    print(f\"\\nLa parola più simile, calcolata tramite {word1} - {word2} + {word3} è: {parola_simile}\")\n",
    "    print(f\"\\nLa parola più simile, calcolata tramite `model.most_similar` è: {result}\")\n",
    "    print(f\"\\nLa similarità del coseno tra il vettore di '{result}' (model.most_similar) e di '{parola_simile}' ({word3} - {word1} + {word2}) è: {similarity:.4f}\\n\\n\")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "fa7efaa698d15c39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T15:46:22.389057Z",
     "start_time": "2025-10-29T15:46:22.254708Z"
    }
   },
   "source": [
    "# esempio classico di re-regina-uomo-donna\n",
    "result = find_analogy(model, \"king\", \"man\", \"woman\")\n",
    "print_analogy_explanation(model, \"king\", \"man\", \"woman\", result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analogia: king - man + woman = ???    ... queen\n",
      "\n",
      "La parola più simile, calcolata tramite king - man + woman è: king\n",
      "\n",
      "La parola più simile, calcolata tramite `model.most_similar` è: queen\n",
      "\n",
      "La similarità del coseno tra il vettore di 'queen' (model.most_similar) e di 'king' (woman - king + man) è: 0.2699\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "14eb4068a7274ea6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T15:46:23.041353Z",
     "start_time": "2025-10-29T15:46:22.405596Z"
    }
   },
   "source": [
    "# esplorazione ulteriori analogie\n",
    "def explore_analogies(model):\n",
    "    print(\"\\nEsploriamo alcune analogie interessanti:\")\n",
    "    analogies = [\n",
    "        (\"king\", \"man\", \"woman\"),\n",
    "        (\"paris\", \"france\", \"italy\"),\n",
    "        (\"doctor\", \"man\", \"woman\"),\n",
    "        (\"highway\", \"car\", \"train\"),\n",
    "        (\"boy\", \"man\", \"woman\")\n",
    "    ]\n",
    "    \n",
    "    for word1, word2, word3 in analogies:\n",
    "        result = find_analogy(model, word1, word2, word3)\n",
    "        if result:\n",
    "            print_analogy_explanation(model, word1, word2, word3, result)\n",
    "        else:\n",
    "            print(f\"\\nNon è stato possibile trovare un'analogia per: {word1} : {word2} :: {word3} : ?\\n\\n\")\n",
    "\n",
    "explore_analogies(model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Esploriamo alcune analogie interessanti:\n",
      "\n",
      "Analogia: king - man + woman = ???    ... queen\n",
      "\n",
      "La parola più simile, calcolata tramite king - man + woman è: king\n",
      "\n",
      "La parola più simile, calcolata tramite `model.most_similar` è: queen\n",
      "\n",
      "La similarità del coseno tra il vettore di 'queen' (model.most_similar) e di 'king' (woman - king + man) è: 0.2699\n",
      "\n",
      "\n",
      "\n",
      "Analogia: paris - france + italy = ???    ... lohan\n",
      "\n",
      "La parola più simile, calcolata tramite paris - france + italy è: paris\n",
      "\n",
      "La parola più simile, calcolata tramite `model.most_similar` è: lohan\n",
      "\n",
      "La similarità del coseno tra il vettore di 'lohan' (model.most_similar) e di 'paris' (italy - paris + france) è: 0.4971\n",
      "\n",
      "\n",
      "\n",
      "Analogia: doctor - man + woman = ???    ... gynecologist\n",
      "\n",
      "La parola più simile, calcolata tramite doctor - man + woman è: doctor\n",
      "\n",
      "La parola più simile, calcolata tramite `model.most_similar` è: gynecologist\n",
      "\n",
      "La similarità del coseno tra il vettore di 'gynecologist' (model.most_similar) e di 'doctor' (woman - doctor + man) è: 0.2723\n",
      "\n",
      "\n",
      "\n",
      "Analogia: highway - car + train = ???    ... railway\n",
      "\n",
      "La parola più simile, calcolata tramite highway - car + train è: highway\n",
      "\n",
      "La parola più simile, calcolata tramite `model.most_similar` è: railway\n",
      "\n",
      "La similarità del coseno tra il vettore di 'railway' (model.most_similar) e di 'highway' (train - highway + car) è: 0.4115\n",
      "\n",
      "\n",
      "\n",
      "Analogia: boy - man + woman = ???    ... girl\n",
      "\n",
      "La parola più simile, calcolata tramite boy - man + woman è: girl\n",
      "\n",
      "La parola più simile, calcolata tramite `model.most_similar` è: girl\n",
      "\n",
      "La similarità del coseno tra il vettore di 'girl' (model.most_similar) e di 'girl' (woman - boy + man) è: 0.0862\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "d3a2babe687d795d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T15:46:23.048648Z",
     "start_time": "2025-10-29T15:46:23.046224Z"
    }
   },
   "source": [
    "# ...try it yourself !\n",
    "#\n",
    "# Provate a creare le vostre analogie e verificatele con il modello\n",
    "# Analizzate i risultati e discutete perché alcune analogie funzionano meglio di altre\n",
    "# Riflettete su possibili bias o limitazioni del modello emersi durante l'esplorazione"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "acf87986dfc8aa1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T15:46:23.054746Z",
     "start_time": "2025-10-29T15:46:23.052982Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
